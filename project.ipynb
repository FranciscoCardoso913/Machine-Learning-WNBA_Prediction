{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T13:59:04.030720Z",
     "start_time": "2024-09-29T13:59:03.008158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-17 16:25:38.762268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734452739.030381    9919 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734452739.111478    9919 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-17 16:25:39.724859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from services.clean_data import *\n",
    "from services.eval import *\n",
    "from services.models import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set maximum rows to None (no truncation)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set maximum columns to None (no truncation)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T13:59:10.590869Z",
     "start_time": "2024-09-29T13:59:10.585440Z"
    }
   },
   "outputs": [],
   "source": [
    "awards_players = clear_awards(pd.read_csv('data/awards_players.csv'))\n",
    "coaches = pd.read_csv('data/coaches.csv')\n",
    "coaches_s11 = pd.read_csv('data/s11/coaches.csv')\n",
    "coaches = clear_coaches(pd.concat([coaches, coaches_s11]))\n",
    "players_teams = pd.read_csv('data/players_teams.csv')\n",
    "players_teams_s11 = pd.read_csv('data/s11/players_teams.csv')\n",
    "players_teams = clear_players_teams(pd.concat([players_teams, players_teams_s11]))\n",
    "players = clear_players(pd.read_csv('data/players.csv'))\n",
    "series_post = clear_series_post(pd.read_csv('data/series_post.csv'))\n",
    "teams_post = clear_teams_post(pd.read_csv('data/teams_post.csv'))\n",
    "df = pd.read_csv('data/teams.csv')\n",
    "df_s11 = pd.read_csv('data/s11/teams.csv')\n",
    "df = clear_teams(pd.concat([df, df_s11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use every table in the input, we need to merge them into the main table. However, since the tables have different sizes, we need to merge them smartly, by adding additional features/columns to the main table which correspond to one or more columns in the other tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the total awards per player for each year\n",
    "player_awards_by_year = awards_players.groupby(['playerID', 'year']).size().reset_index(name='awards_count')\n",
    "\n",
    "# Step 2: Ensure all years are represented for each player\n",
    "# Create a full set of years for each player\n",
    "all_years = pd.DataFrame({'year': range(1, awards_players['year'].max() + 1)})  # Assuming years start from 1\n",
    "player_years = player_awards_by_year['playerID'].unique()\n",
    "full_player_data = pd.DataFrame([(player, year) for player in player_years for year in range(1, awards_players['year'].max() + 1)], columns=['playerID', 'year'])\n",
    "\n",
    "# Merge with original player data to fill in missing years (with NaN awards_count for missing years)\n",
    "player_awards_by_year = pd.merge(full_player_data, player_awards_by_year, on=['playerID', 'year'], how='left')\n",
    "\n",
    "# Fill missing awards_count with 0 where no award was given that year\n",
    "player_awards_by_year['awards_count'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 3: Calculate cumulative awards per player (cumsum over awards_count)\n",
    "player_awards_by_year['cumulative_awards'] = player_awards_by_year.groupby('playerID')['awards_count'].cumsum()\n",
    "\n",
    "# Step 4: Calculate total awards per coach for each year (using coachID instead of playerID)\n",
    "coach_awards_by_year = awards_players[awards_players['playerID'].isin(coaches['coachID'])]\n",
    "coach_awards_by_year = coach_awards_by_year.groupby(['playerID', 'year']).size().reset_index(name='awards_count')\n",
    "\n",
    "# Step 5: Ensure all years are represented for each coach\n",
    "# Create a full set of years for each coach\n",
    "coach_ids = coach_awards_by_year['playerID'].unique()  # Same as 'coachID' here\n",
    "full_coach_data = pd.DataFrame([(coach, year) for coach in coach_ids for year in range(1, awards_players['year'].max() + 1)], columns=['playerID', 'year'])\n",
    "\n",
    "# Merge with original coach data to fill in missing years\n",
    "coach_awards_by_year = pd.merge(full_coach_data, coach_awards_by_year, on=['playerID', 'year'], how='left')\n",
    "\n",
    "# Fill missing awards_count with 0 where no award was given that year\n",
    "coach_awards_by_year['awards_count'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 6: Calculate cumulative awards per coach (cumsum over awards_count)\n",
    "coach_awards_by_year['cumulative_awards'] = coach_awards_by_year.groupby('playerID')['awards_count'].cumsum()\n",
    "\n",
    "# Rename playerID to coachID to distinguish coaches\n",
    "coach_awards_by_year.rename(columns={'playerID': 'coachID'}, inplace=True)\n",
    "\n",
    "# Combine both player and coach awards\n",
    "combined_awards_by_year = pd.concat([player_awards_by_year, coach_awards_by_year])\n",
    "\n",
    "# Step 7: Merging with the next year's stats (for players and coaches)\n",
    "# Shift players_teams data to associate players of year X+1 with teams in year X\n",
    "players_teams_next_year = players_teams.copy()\n",
    "players_teams_next_year['year'] -= 1  # Shift years back to merge with current awards\n",
    "players_teams_next_year = players_teams_next_year[players_teams_next_year['year'] > 0]\n",
    "\n",
    "# Merge cumulative awards for players\n",
    "team_players_awards = pd.merge(\n",
    "    players_teams_next_year,\n",
    "    combined_awards_by_year[['playerID', 'year', 'cumulative_awards']],\n",
    "    on=['playerID', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Shift coaches data to associate coaches of year X+1 with teams in year X\n",
    "coaches_next_year = coaches.copy()\n",
    "coaches_next_year['year'] -= 1  # Shift years back to merge with current awards\n",
    "coaches_next_year = coaches_next_year[coaches_next_year['year'] > 0]\n",
    "\n",
    "# Merge cumulative awards for coaches\n",
    "team_coaches_awards = pd.merge(\n",
    "    coaches_next_year,\n",
    "    combined_awards_by_year[['coachID', 'year', 'cumulative_awards']],\n",
    "    on=['coachID', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 8: Combine and Aggregate\n",
    "# Standardize column names to allow concatenation\n",
    "team_coaches_awards = team_coaches_awards.rename(columns={'coachID': 'playerID'})  # Treat coaches as players for processing\n",
    "\n",
    "# Concatenate player and coach awards\n",
    "team_players_awards = pd.concat([team_players_awards, team_coaches_awards], ignore_index=True)\n",
    "\n",
    "# Group by team and year, summing cumulative awards\n",
    "team_players_awards = team_players_awards.groupby(['tmID', 'year'], as_index=False).agg({'cumulative_awards': 'sum'})\n",
    "\n",
    "# Fill missing values (for players/coaches with no awards) with 0\n",
    "team_players_awards['cumulative_awards'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 9: Merge the result with the main team dataframe (df)\n",
    "df = df.merge(team_players_awards[['tmID', 'year', 'cumulative_awards']], on=['tmID', 'year'], how='left')\n",
    "\n",
    "# Fill missing values for teams that don't have any data for the next year\n",
    "df['cumulative_awards'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate cumulative stats for each coach (up to their current year)\n",
    "coaches['cumulative_wins'] = coaches.groupby('coachID')['coach_won'].cumsum()\n",
    "coaches['cumulative_losses'] = coaches.groupby('coachID')['coach_lost'].cumsum()\n",
    "coaches['cumulative_WR'] = coaches['cumulative_wins'] / (coaches['cumulative_wins'] + coaches['cumulative_losses'])\n",
    "\n",
    "# Step 2: Shift the year for coaches to assign the correct future coach for each team\n",
    "future_coaches = coaches[['coachID', 'tmID', 'year']].copy()\n",
    "future_coaches['year'] = future_coaches['year'] + 1  # Assign future coach to the current year (team year)\n",
    "\n",
    "# Step 3: Merge cumulative WR for the coaches on the team (using current year stats for the future coach)\n",
    "cumulative_stats = coaches[['coachID', 'year', 'cumulative_WR']]\n",
    "future_coaches_stats = pd.merge(future_coaches, cumulative_stats, on=['coachID', 'year'], how='left')\n",
    "\n",
    "# Step 4: Merge future coaches' stats into the teams DataFrame\n",
    "df = pd.merge(df, future_coaches_stats, on=['tmID', 'year'], how='left')\n",
    "\n",
    "# Step 5: Handle missing values (teams with no coach yet assigned in future years)\n",
    "df['cumulative_WR'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 6: Separate for first and second coaches\n",
    "# For teams with a second coach (stint == 2), we'll create secondCoachWR\n",
    "first_coach_wr = coaches[coaches['stint'] == 1][['year', 'tmID', 'cumulative_WR']].rename(columns={'cumulative_WR': 'firstCoachWR'})\n",
    "second_coach_wr = coaches[coaches['stint'] == 2][['year', 'tmID', 'cumulative_WR']].rename(columns={'cumulative_WR': 'secondCoachWR'})\n",
    "\n",
    "# For teams where the same coach is assigned to both positions (stint == 0), we'll use the same WR\n",
    "same_coach_wr = coaches[coaches['stint'] == 0][['year', 'tmID', 'cumulative_WR']]\n",
    "same_coach_wr['firstCoachWR'] = same_coach_wr['cumulative_WR']\n",
    "same_coach_wr['secondCoachWR'] = same_coach_wr['cumulative_WR']\n",
    "same_coach_wr = same_coach_wr[['year', 'tmID', 'firstCoachWR', 'secondCoachWR']]\n",
    "\n",
    "# Combine the coach data for first and second coach WR\n",
    "combined_coach_wr = pd.concat([first_coach_wr, second_coach_wr, same_coach_wr], axis=0).drop_duplicates(subset=['year', 'tmID'])\n",
    "\n",
    "# Step 7: Merge combined coach WR data into the teams DataFrame (df)\n",
    "df = pd.merge(df, combined_coach_wr, on=['tmID', 'year'], how='left')\n",
    "\n",
    "# Step 8: Fill missing values with 0 where no coach data exists\n",
    "df['firstCoachWR'].fillna(0, inplace=True)\n",
    "df['secondCoachWR'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 9: Clean up the data to make sure no duplicate team-year pairs exist\n",
    "df = df.drop_duplicates(subset=['tmID', 'year'])\n",
    "\n",
    "# Step 10: Final sort and display (optional for cleaner output)\n",
    "df.sort_values(by=['franchID', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_best_players = players_teams.groupby('playerID')[\"points\"].sum().reset_index().sort_values(by=['points'], ascending=False)\n",
    "top_all_time_best_players = all_time_best_players.merge(players_teams, on=['playerID']).groupby('playerID')\n",
    "top_all_time_best_players = top_all_time_best_players.head(5)\n",
    "\n",
    "tmid_counts = top_all_time_best_players['tmID'].value_counts().reset_index()\n",
    "tmid_counts.columns = ['tmID', 'tmID_count']\n",
    "\n",
    "tmid_counts = tmid_counts.rename(columns={'tmID_count': 'number_of_top_players'})\n",
    "\n",
    "df = df.merge(tmid_counts, on=['tmID'], how='left')\n",
    "df['number_of_top_players'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shot_accuracy'] = (df['o_fgm'] + df['o_3pm']) / (df['o_fga']+ df['o_3pa'])\n",
    "df['defensive_accuracy'] = (df['d_fgm'] + df['d_ftm'] + df['d_3pm']) / (df['d_fga'] + df['d_fta'] + df['d_3pa'])\n",
    "df['win_rate'] = (df['won']) / (df['won'] + df['lost'])\n",
    "df[\"fg_effeciency\"] = (df['o_fgm']  + df['o_3pm']*0.5 )/ (df['o_fga'])\n",
    "df[\"shoot_percentage\"] = (df['o_pts']  )/ (2*(df['o_fga']+0.44*df['o_fta']))\n",
    "df.loc[df['year'] == 11, 'playoff'] = 'N' # No playoffs in year 11 since it is unknown\n",
    "df[\"n_playoff\"] = (\n",
    "    df.assign(playoff_numeric=(df[\"playoff\"] == 'Y'))\n",
    "    .groupby(\"franchID\")[\"playoff_numeric\"]  # Group by team\n",
    "    .cumsum()  # Cumulative sum of playoff appearances\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
